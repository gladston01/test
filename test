import sys
from bs4 import BeautifulSoup
import re
import argparse

# Function to extract error messages from relevant tags
def extract_error_message(failure_soup):
    # Define the list of specific error tags
    error_tags = [
        re.compile(r".*:errorText$"),  # Handles dynamic prefixes like <ns1:errorText>
        "messageText",
        "message",
        "SerErrorMessage",
    ]

    # Look for specific error tags
    for tag in error_tags:
        if isinstance(tag, str):
            found_tag = failure_soup.find(tag)
        else:  # Regex matching for dynamic tag names
            found_tag = failure_soup.find(lambda t: t.name and tag.match(t.name))

        if found_tag:
            return found_tag.text.strip()

    # If no specific error tags are found, look for broader tags
    relevant_tags = ["pre", "h3", "b"]
    error_messages = []

    for tag in relevant_tags:
        found_tags = failure_soup.find_all(tag)
        for found in found_tags:
            # Extract text and clean it
            text = found.get_text(strip=True)
            if text:  # Avoid adding empty text
                error_messages.append(text)

    # Join all found messages, if any, or return a default message
    if error_messages:
        return " | ".join(error_messages)
    return "No meaningful error message found."

# Set up argument parser
parser = argparse.ArgumentParser(description="Extract failure details from an HTML file.")
parser.add_argument("--html-location", required=True, help="Path to the HTML file containing failure details.")
args = parser.parse_args()

input_file = args.html_location

# Read the input HTML file
try:
    with open(input_file, 'r', encoding='utf-8') as file:
        html_content = file.read()
except FileNotFoundError:
    print(f"Error: File '{input_file}' not found.")
    sys.exit(1)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(html_content, 'html.parser')

# Find all failure rows
failure_rows = soup.find_all('tr', class_='Failure')

# Prepare to write to output file
output_file = 'extracted_failures.txt'

with open(output_file, 'w', encoding='utf-8') as output:
    for row in failure_rows:
        # Extract the test case name from the second <td> element's <a name> attribute
        test_case_name = row.find_all('td')[1].find('a').get('name', 'Unknown Test Case')

        # Extract all test step names and their failure details
        failure_details_html = row.find_all('td')[3]
        failure_soup = BeautifulSoup(str(failure_details_html), 'html.parser')

        test_step_matches = re.findall(r'TestStep:\s*(\w+)', str(failure_details_html))

        if not test_step_matches:
            output.write(f"Warning: No test steps found for Test Case: {test_case_name}\n")
            output.write("-" * 40 + "\n")
            continue

        for test_step_name in test_step_matches:
            # Extract the failure reason for each test step
            failure_reason = extract_error_message(failure_soup)

            # Write the extracted information to the output file
            output.write(f"Test Case Name: {test_case_name}\n")
            output.write(f"Test Step Name: {test_step_name}\n")
            output.write(f"Failure Reason: {failure_reason}\n")
            output.write("-" * 40 + "\n")

print(f"Extraction completed. Check the file '{output_file}' for details.")
