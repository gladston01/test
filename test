import os
import re
import argparse
import pandas as pd
import psycopg2
from psycopg2.extras import DictCursor
import logging
from datetime import datetime, timedelta

# Logging setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

# Constants for JTL column names
JTL_COLUMNS = [
    "timeStamp", "elapsed", "label", "responseCode", "responseMessage",
    "threadName", "dataType", "success", "failureMessage", "bytes", "sentBytes",
    "grpThreads", "allThreads", "URL", "Latency", "IdleTime", "Connect"
]

def extract_uri(url):
    """Extract the URI path from the URL, including the version.

    Args:
        url (str): The URL from which to extract the URI.

    Returns:
        tuple: A tuple containing the base URI path and the version, or None if extraction fails.
    """
    if not isinstance(url, str):
        return None, None
    match = re.search(r'(https?://[^/]+)(/[^\?]*)/v(\d+)', url)
    if match:
        return match.group(2) + '/', 'v' + match.group(3)
    return None, None

def load_jtl(jtl_filepath):
    """Load JTL file into a DataFrame and process URIs.

    Args:
        jtl_filepath (str): Path to the JTL file.

    Returns:
        pd.DataFrame: A DataFrame containing processed JTL data with extracted URIs.
        None: If the JTL file is missing or cannot be processed.
    """
    if not os.path.exists(jtl_filepath):
        logging.error(f"JTL file not found: {jtl_filepath}")
        return None

    try:
        df = pd.read_csv(jtl_filepath, names=JTL_COLUMNS, header=0, dtype={'responseCode': 'object'}, low_memory=True)
        df[['URI', 'Version']] = df['URL'].apply(lambda x: pd.Series(extract_uri(x)))
        df.dropna(subset=['URI', 'elapsed'], inplace=True)
        return df
    except FileNotFoundError as e:
        logging.error(f"Error reading JTL file: {e}")
        return None

def query_pgsql_bulk(uris, connection, mode):
    """Query the PostgreSQL table for all URIs in bulk.

    Args:
        uris (list): List of URIs to query.
        connection (psycopg2.Connection): A connection object to the PostgreSQL database.
        mode (str): The mode of comparison ('previousMonth' or 'peakMonth').

    Returns:
        dict: A dictionary with URIs as keys and production statistics as values.
    """
    results = {}
    try:
        with connection.cursor(cursor_factory=DictCursor) as cursor:
            if mode == 'previousMonth':
                last_month_start = (datetime.now().replace(day=1) - timedelta(days=1)).replace(day=1)
                last_month_end = datetime.now().replace(day=1) - timedelta(days=1)

                query = """
                    SELECT "uriPath", "Date", "avg", "p95"
                    FROM "DataPower".monthlysplit
                    WHERE "uriPath" = ANY(%s) AND "Date" BETWEEN %s AND %s
                    ORDER BY "Date" DESC
                """
                cursor.execute(query, (uris, last_month_start, last_month_end))

            elif mode == 'peakMonth':
                query = """
                    SELECT DISTINCT ON ("uriPath") "uriPath", "Date", "avg", "p95"
                    FROM "DataPower".monthlysplit
                    WHERE "uriPath" = ANY(%s)
                    ORDER BY "uriPath", "grpThreads" DESC, "Date" DESC
                """
                cursor.execute(query, (uris,))

            for row in cursor.fetchall():
                results[row["uriPath"]] = row

    except psycopg2.Error as e:
        logging.error(f"Error querying database in mode {mode}: {e}")
    return results

def process_statistics(df, connection, output_file, comparison_mode):
    """Process statistics for each unique URI and compare with production data.

    Args:
        df (pd.DataFrame): DataFrame containing the test statistics.
        connection (psycopg2.Connection): Connection to the PostgreSQL database.
        output_file (str): Path to the output file for storing comparison results.
        comparison_mode (str): The mode of comparison ('previousMonth' or 'peakMonth').

    Returns:
        None
    """
    unique_uris = df['URI'].unique()
    # Query production data in bulk
    production_data = query_pgsql_bulk(unique_uris.tolist(), connection, comparison_mode)

    # Group the DataFrame by URI to process test stats
    grouped = df.groupby('URI')

    with open(output_file, 'w') as f:
        f.write("Slack Notification Content:\n")
        f.write("==========================\n\n")

        for uri, group in grouped:
            version = group['Version'].iloc[0]
            test_avg = group['elapsed'].mean()
            test_p95 = group['elapsed'].quantile(0.95)

            prod_data = production_data.get(uri)
            if prod_data:
                prod_date = prod_data['Date']
                prod_avg = prod_data['avg']
                prod_p95 = prod_data['p95']

                f.write(f"{uri}{version}\n")
                f.write(f"Test statistics: Avg - {test_avg:.2f}, 95% - {test_p95:.2f}\n")
                f.write(f"Production ({comparison_mode} data - {prod_date}): Avg - {prod_avg:.2f}, 95% - {prod_p95:.2f}\n\n")
            else:
                f.write(f"{uri}{version}\n")
                f.write(f"Test statistics: Avg - {test_avg:.2f}, 95% - {test_p95:.2f}\n")
                f.write("Service not found in production stats, possible new service.\n\n")

def main():
    """Main function to orchestrate the process."""
    parser = argparse.ArgumentParser(description="Analyze JTL files and compare with production data.")
    parser.add_argument("--jtl-file", required=True, help="Path to the JTL file")
    parser.add_argument("--output-dir", default="output/reports", help="Directory to store the output report")
    parser.add_argument("--comparison-mode", choices=["previousMonth", "peakMonth"], default="previousMonth",
                        help="Comparison mode to use")
    parser.add_argument("--db-name", required=True, help="Database name")
    parser.add_argument("--db-user", required=True, help="Database user")
    parser.add_argument("--db-password", required=True, help="Database password")
    parser.add_argument("--db-host", required=True, help="Database host")
    parser.add_argument("--db-port", required=True, help="Database port")

    args = parser.parse_args()

    db_config = {
        'dbname': args.db_name,
        'user': args.db_user,
        'password': args.db_password,
        'host': args.db_host,
        'port': args.db_port
    }

    os.makedirs(args.output_dir, exist_ok=True)
    output_file = os.path.join(args.output_dir, 'URI_comparison_report.txt')

    # Load JTL data
    df = load_jtl(args.jtl_file)
    if df is None:
        logging.error("Failed to process JTL file.")
        return

    # Connect to PostgreSQL
    try:
        connection = psycopg2.connect(**db_config)
        process_statistics(df, connection, output_file, args.comparison_mode)
        logging.info(f"Report generated successfully at {output_file}")
    except psycopg2.Error as e:
        logging.exception("Database error occurred while processing.")
    except FileNotFoundError as e:
        logging.exception("JTL file not found.")
    finally:
        if connection:
            connection.close()

if __name__ == "__main__":
    main()
